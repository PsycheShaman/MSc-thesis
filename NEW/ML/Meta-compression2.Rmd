---
title: "Meta-compression2"
author: "Gerhard Viljoen"
date: "31/08/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
rm(list=ls())

# load("C:/Users/gerhard/documents/msc-thesis-data/meta.rdata")
load("C:/Users/Gerhard/Documents/msc-thesis-data/aux_.rdata")
load("C:/Users/gerhard/documents/msc-thesis-data/y.rdata")
load("C:/Users/gerhard/documents/msc-thesis-data/x.rdata")
```


```{r}
P <- as.numeric(as.character(aux$P))
rm(aux)
```

```{r}
P1 <- which(P<=1)
P2 <- which(P<=2&P>1)
P3 <- which(P<=3&P>2)
P4 <- which(P<=4&P>3)
P5 <- which(P<=5&P>4)
P6 <- which(P<=6&P>5)

rm(P,P1)
```


```{r}
x2 <- x[P2,]
x3 <- x[P3,]
x4 <- x[P4,]
x5 <- x[P5,]
x6 <- x[P6,]

y2 <- y[P2]
y3 <- y[P3]
y4 <- y[P4]
y5 <- y[P5]
y6 <- y[P6]

rm(x,P2,P3,P4,P5,P6)
rm(y)
```

```{r}
save(x2,file="C:/Users/gerhard/documents/msc-thesis-data/x_P2")
save(x3,file="C:/Users/gerhard/documents/msc-thesis-data/x_P3")
save(x4,file="C:/Users/gerhard/documents/msc-thesis-data/x_P4")
save(x5,file="C:/Users/gerhard/documents/msc-thesis-data/x_P5")
save(x6,file="C:/Users/gerhard/documents/msc-thesis-data/x_P6")

save(y2,file="C:/Users/gerhard/documents/msc-thesis-data/y_P2")
save(y3,file="C:/Users/gerhard/documents/msc-thesis-data/y_P3")
save(y4,file="C:/Users/gerhard/documents/msc-thesis-data/y_P4")
save(y5,file="C:/Users/gerhard/documents/msc-thesis-data/y_P5")
save(y6,file="C:/Users/gerhard/documents/msc-thesis-data/y_P6")
```

```{r}

table(y2)

pid_per_p <- cbind(
  rbind(
  as.numeric(table(y2)),
  as.numeric(table(y3)),
  as.numeric(table(y4)),
  as.numeric(table(y5)),
  as.numeric(table(y6))
),
c("P<=2","2<P<=3","3<P<=4","4<P<=5","5<P<=6")
)

pid_per_p <- cbind(c(pid_per_p[,1],pid_per_p[,2]),rep(pid_per_p[,3],2))

pid <- c(rep("pion",5),rep("electron",5))

pid_per_p <- data.frame(cbind(pid_per_p,pid))

names(pid_per_p)[1:2] <- c("count","Momentum Range")

pid_per_p$count <- as.numeric(as.character(pid_per_p$count))

require(ggplot2)

ggplot(pid_per_p,aes(x=count))

ggplot(pid_per_p,aes(y=pid_per_p$count,fill=pid,color=pid,x=pid))+geom_col()+facet_wrap(~`Momentum Range`)+xlab("Particle ID")+ylab("Number of Particles per Momentum Range")

```


```{r}
rm(x3,x4,x5,x6)
rm(y3,y4,y5,y6)
rm(pid_per_p)
```


```{r}
dim(x2)
dim(x2) <- c(dim(x2)[1],17,24,1)

x <- (x2-max(x2))/max(x2)

```

```{r}
rm(list=ls())
load("C:/Users/gerhard/documents/msc-thesis-data/x_P2")
load("C:/Users/gerhard/documents/msc-thesis-data/y_P2")
```

```{r}
# dim(x2)
dim(x2) <- c(dim(x2)[1],17,24,1)

# x <- (x2-max(x2))/max(x2)

any(is.na(x2))

```


```{python,eval=F}
def focal_loss(gamma=2., alpha=.25):

	def focal_loss_fixed(y_true, y_pred):
	
		pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))
	
		pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))
	
		return -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) - K.mean((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))
	
	return focal_loss_fixed

```


```{r}
require(keras)

require(tensorflow)

K <- keras::backend()

# Custom Focal Loss

fokLos <- function(gamma=2., alpha=.25){
  
  loss <- function(y_true,y_pred){
  
  pt_1 <- tf$where(tf$equal(y_true,1),y_pred,tf$ones_like(y_pred))
  
  pt_0 <- tf$where(tf$equal(y_true,0),y_pred,tf$ones_like(y_pred))
  
  #clip to prevent NaNs and Infs
  
  epsilon <- K$epsilon()
  
  pt_1 <- K$clip(pt_1,epsilon,1.-epsilon)
  pt_0 <- K$clip(pt_0,epsilon,1.-epsilon)
  
  return(-K$mean(alpha*K$pow(1.-pt_1,gamma)*K$log(pt_1))-K$mean((1-alpha)*K$pow(pt_0,gamma)*K$log(1.-pt_0)))
    
  }
  
 return(loss)
}

```

```{r}
model <- keras_model_sequential() %>%
  layer_conv_2d(input_shape = c(17,24,1),filters = 128,kernel_size = c(3,3),padding = "same",activation = "relu") %>%
  layer_max_pooling_2d() %>%
  layer_conv_2d(64,c(3,3),activation = "relu",padding="same") %>%
  layer_max_pooling_2d() %>%
  layer_conv_2d(32,c(3,3),activation = "relu",padding="same") %>%
  layer_max_pooling_2d() %>%
  layer_conv_2d(16,c(3,3),activation = "relu",padding="same") %>%
  layer_max_pooling_2d() %>%
  layer_conv_2d(8,c(3,3),activation = "relu",padding="same") %>%
  layer_flatten() %>%
  layer_dense(512,"relu") %>%
  layer_dense(1,activation = "sigmoid")



model %>% compile(
  loss = fokLos(),
  optimizer = optimizer_adam(),
  metrics = c("accuracy")
)

history <- model %>% fit(
  x2, y2, 
  epochs = 30, batch_size = 32, 
  validation_split = 0.2,
  shuffle=T
)
```


![](C:/Users/gerhard/Documents/MSc-thesis/NEW/ML/focal_loss_1.png)

```{r}
rm(list=ls())
load("C:/Users/gerhard/documents/msc-thesis-data/x_P2")
load("C:/Users/gerhard/documents/msc-thesis-data/y_P2")
```

```{r}
# dim(x2)
dim(x2) <- c(dim(x2)[1],17,24,1)

x <- (x2-max(x2))/max(x2)

```


```{r}
require(keras)

require(tensorflow)

K <- keras::backend()

# Custom Focal Loss

fokLos <- function(gamma=2., alpha=.25){
  
  loss <- function(y_true,y_pred){
  
  pt_1 <- tf$where(tf$equal(y_true,1),y_pred,tf$ones_like(y_pred))
  
  pt_0 <- tf$where(tf$equal(y_true,0),y_pred,tf$ones_like(y_pred))
  
  #clip to prevent NaNs and Infs
  
  epsilon <- K$epsilon()
  
  pt_1 <- K$clip(pt_1,epsilon,1.-epsilon)
  pt_0 <- K$clip(pt_0,epsilon,1.-epsilon)
  
  return(-K$mean(alpha*K$pow(1.-pt_1,gamma)*K$log(pt_1))-K$mean((1-alpha)*K$pow(pt_0,gamma)*K$log(1.-pt_0)))
    
  }
  
 return(loss)
}

```

```{r}
#Benchmark
1- length(which(y2==1))/length(y2)
#0.7651971

model <- keras_model_sequential() %>%
  layer_conv_2d(input_shape = c(17,24,1),filters = 32,kernel_size = c(6,6),padding = "same",activation = "tanh") %>%
  layer_max_pooling_2d() %>%
  layer_dropout(rate=0.2) %>%
  layer_conv_2d(64,c(3,3),activation = "tanh",padding="same") %>%
  layer_max_pooling_2d() %>%
  layer_dropout(rate=0.2) %>%
  layer_conv_2d(128,c(3,3),activation = "tanh",padding="same") %>%
  layer_max_pooling_2d() %>%
  layer_dropout(rate=0.2) %>%
  layer_flatten() %>%
  layer_dense(512,"tanh") %>%
  layer_dropout(rate=0.2) %>%
  layer_dense(256,"tanh") %>%
  layer_dropout(rate=0.2) %>%
  layer_dense(128,"tanh") %>%
  layer_dropout(rate=0.2) %>%
  layer_dense(1,activation = "sigmoid")



model %>% compile(
  loss = fokLos(),
  optimizer = optimizer_adam(lr=0.00001),
  metrics = c("accuracy")
)

history <- model %>% fit(
  x2, y2, 
  epochs = 10, batch_size = 32, 
  validation_split = 0.2,
  shuffle=T
)

plot(history)
```


![](C:/Users/gerhard/Documents/MSc-thesis/NEW/ML/focal_loss_2.png)

```{r}
history <- model %>% fit(
  x2, y2, 
  epochs = 30, batch_size = 32, 
  validation_split = 0.2,
  shuffle=T,
  initial_epoch = 10
)

plot(history)
```

![](C:/Users/gerhard/Documents/MSc-thesis/NEW/ML/focal_loss_3.png)


```{r}
save_model_hdf5(model, "C:/Users/gerhard/Documents/MSc-thesis/NEW/ML/model_focal_loss_lte_2_GeV.h5", overwrite = TRUE,
  include_optimizer = TRUE)
```

```{r}
rm(list=ls())

require(keras)

K <- keras::backend()

fokLos <- function(gamma=2., alpha=.25){
  
  loss <- function(y_true,y_pred){
  
  pt_1 <- tf$where(tf$equal(y_true,1),y_pred,tf$ones_like(y_pred))
  
  pt_0 <- tf$where(tf$equal(y_true,0),y_pred,tf$ones_like(y_pred))
  
  #clip to prevent NaNs and Infs
  
  epsilon <- K$epsilon()
  
  pt_1 <- K$clip(pt_1,epsilon,1.-epsilon)
  pt_0 <- K$clip(pt_0,epsilon,1.-epsilon)
  
  return(-K$mean(alpha*K$pow(1.-pt_1,gamma)*K$log(pt_1))-K$mean((1-alpha)*K$pow(pt_0,gamma)*K$log(1.-pt_0)))
    
  }
  
 return(loss)
}

# fokLos <- function(gamma=2., alpha=.25){
#   
#   loss <- custom_metric(c("fokLos"),
#     
#                         function(y_true,y_pred){
#   
#   pt_1 <- tf$where(tf$equal(y_true,1),y_pred,tf$ones_like(y_pred))
#   
#   pt_0 <- tf$where(tf$equal(y_true,0),y_pred,tf$ones_like(y_pred))
#   
#   #clip to prevent NaNs and Infs
#   
#   epsilon <- K$epsilon()
#   
#   pt_1 <- K$clip(pt_1,epsilon,1.-epsilon)
#   pt_0 <- K$clip(pt_0,epsilon,1.-epsilon)
#   
#   return(-K$mean(alpha*K$pow(1.-pt_1,gamma)*K$log(pt_1))-K$mean((1-alpha)*K$pow(pt_0,gamma)*K$log(1.-pt_0)))
#     
#   }
#     
#   ) 
#   
#  return(loss)
#   
#   
# }

model <- keras_model_sequential() %>%
  layer_conv_2d(input_shape = c(17,24,1),filters = 32,kernel_size = c(6,6),padding = "same",activation = "tanh") %>%
  layer_max_pooling_2d() %>%
  layer_dropout(rate=0.2) %>%
  layer_conv_2d(64,c(3,3),activation = "tanh",padding="same") %>%
  layer_max_pooling_2d() %>%
  layer_dropout(rate=0.2) %>%
  layer_conv_2d(128,c(3,3),activation = "tanh",padding="same") %>%
  layer_max_pooling_2d() %>%
  layer_dropout(rate=0.2) %>%
  layer_flatten() %>%
  layer_dense(512,"tanh") %>%
  layer_dropout(rate=0.2) %>%
  layer_dense(256,"tanh") %>%
  layer_dropout(rate=0.2) %>%
  layer_dense(128,"tanh") %>%
  layer_dropout(rate=0.2) %>%
  layer_dense(1,activation = "sigmoid")

model <- keras::load_model_weights_hdf5(model,filepath = "C:/Users/gerhard/Documents/MSc-thesis/NEW/ML/model_focal_loss_lte_2_GeV.h5")

# 
# with_custom_object_scope(c(fokLos = fokLos()),
# 
# {
#   
#   model <- load_model_hdf5("C:/Users/gerhard/Documents/MSc-thesis/NEW/ML/model_focal_loss_lte_2_GeV.h5",custom_objects = c("fokLos"=fokLos))
# })
#   
# 
# model <- load_model_hdf5("C:/Users/gerhard/Documents/MSc-thesis/NEW/ML/model_focal_loss_lte_2_GeV.h5",custom_objects = c("fokLos()"=fokLos))
  
  
```



```{r}


load("C:/Users/gerhard/documents/msc-thesis-data/x_P2")
load("C:/Users/gerhard/documents/msc-thesis-data/y_P2")
```

```{r}
# dim(x2)
dim(x2) <- c(dim(x2)[1],17,24,1)

x <- (x2-max(x2))/max(x2)

```



```{r}
preds <- predict(model,x2)

pred_act <- cbind(preds,y2)
```


```{r}
pred_act <- data.frame(pred_act)

names(pred_act) <- c("pred","act")

pi <- which(pred_act$act==1)
el <- which(pred_act$act!=1)

while(length(pi)%%6!=0){
  #print(length(pi))
  pi <- pi[-length(pi)]
  
}

while(length(el)%%6!=0){
  #print(length(el))
  el <- el[-length(el)]
  
}

pred_act <- pred_act[c(el,pi),]

six_tracklet_pred <- c()

for(i in seq(1,nrow(pred_act),6)){
  j=i+5
  
  this.dat <- prod(pred_act$pred[i:j])/sum(prod(pred_act$pred[i:j]),prod(1-pred_act$pred[i:j]))
  
  six_tracklet_pred <- c(six_tracklet_pred,this.dat)
}

six_tracklet_pred <- data.frame(six_tracklet_pred)

six_tracklet_pred <- na.omit(six_tracklet_pred)

six_tracklet_real <- c()

for(i in seq(1,nrow(pred_act),6)){
  this.dat <- pred_act$act[i]
  six_tracklet_real <- c(six_tracklet_real,this.dat)
  
}

six_tracklet_real <- data.frame(six_tracklet_real)

which(is.na(six_tracklet_real))

pred_act <- data.frame(cbind(six_tracklet_pred,six_tracklet_real))

elec_pi_eff_func <- function(model_1.preds,model_1.labels){
  
    # model_1.preds <- read.csv(model_1.preds,header=F, sep="")
    # 
    # model_1.labels <- read.csv(model_1.labels,header=F, sep="")
    
    model_1 <- data.frame(cbind(model_1.preds,model_1.labels))
    
    model_1.electrons <- which(model_1[,2]==1)
    
    electrons <- model_1[model_1.electrons,]
    
    pions <- model_1[-as.numeric(model_1.electrons),]
    
    electrons <- data.frame(electrons)
    
    names(electrons) <- c("prediction","label")
    
    pions <- data.frame(pions)
    
    names(pions) <- c("prediction","label")
    
    electron_efficiency <- function(electrons.,par){
  
    electrons <- electrons.
    
    electrons$electron_pred <- ifelse(electrons$prediction>=par[1],1,0)
    
    correct <- ifelse(electrons$electron_pred==electrons$label,1,0)
    
    error_metric <- sum(correct)/nrow(electrons)
    
    error_metric <- (error_metric-0.9)^2
    
    return(error_metric)
  
}

  res <- optim(par=c(0),fn=electron_efficiency,lower = 0,upper = 1,electrons.=electrons,method="Brent")
  
  require(ggplot2)
  
  g <- ggplot(pred_act,aes(pred_act[,1],colour=factor(pred_act[,2])))+geom_histogram(bins = 1000)+facet_wrap(factor(pred_act[,2]))
  print(g)
  
  hist(pred_act[,1],breaks=1000)
  abline(v=res$par,col="red")
  
  electrons$predicted_label <- ifelse(electrons$prediction>=res$par,1,0)
  
  print(paste0("Electron Efficiency: ",sum(electrons$predicted_label)/nrow(electrons)))
  
  pions$predicted_label <- ifelse(pions$prediction>=res$par,1,0)
  
  pions$misclassified_as_electron <- ifelse(pions$predicted_label==1,1,0)
  
  print(paste0("Pion Efficiency: ",(sum(pions$misclassified_as_electron)/nrow(pions))))
  
  pred_act$final_pred <- ifelse(pred_act[,1]>=res$par,1,0)
  
  require(caret)
  
  print(caret::confusionMatrix(data=factor(pred_act$final_pred),reference = factor(pred_act[,2])))
  print("--------------------------------------------------------------------------------------------------")
  
}

elec_pi_eff_func(pred_act[,1],pred_act[,2])
```


```{r}
rm(x,x2,y2)
```


```{r}
rm(list=ls())

load("C:/Users/gerhard/documents/msc-thesis-data/x_P3")
load("C:/Users/gerhard/documents/msc-thesis-data/y_P3")

# dim(x2)
dim(x3) <- c(dim(x3)[1],17,24,1)

# x <- (x3-max(x3))/max(x3)

```

```{r}
require(keras)

model <- keras_model_sequential() %>%
  layer_conv_2d(input_shape = c(17,24,1),filters = 32,kernel_size = c(6,6),padding = "same",activation = "tanh") %>%
  layer_max_pooling_2d() %>%
  layer_dropout(rate=0.2) %>%
  layer_conv_2d(64,c(3,3),activation = "tanh",padding="same") %>%
  layer_max_pooling_2d() %>%
  layer_dropout(rate=0.2) %>%
  layer_conv_2d(128,c(3,3),activation = "tanh",padding="same") %>%
  layer_max_pooling_2d() %>%
  layer_dropout(rate=0.2) %>%
  layer_flatten() %>%
  layer_dense(512,"tanh") %>%
  layer_dropout(rate=0.2) %>%
  layer_dense(256,"tanh") %>%
  layer_dropout(rate=0.2) %>%
  layer_dense(128,"tanh") %>%
  layer_dropout(rate=0.2) %>%
  layer_dense(1,activation = "sigmoid")

model <- keras::load_model_weights_hdf5(model,filepath = "C:/Users/gerhard/Documents/MSc-thesis/NEW/ML/model_focal_loss_lte_2_GeV.h5")

```




```{r}
preds <- predict(model,x3)

pred_act <- cbind(preds,y3)

pred_act <- data.frame(pred_act)

names(pred_act) <- c("pred","act")

pi <- which(pred_act$act==1)
el <- which(pred_act$act!=1)

while(length(pi)%%6!=0){
  #print(length(pi))
  pi <- pi[-length(pi)]
  
}

while(length(el)%%6!=0){
  #print(length(el))
  el <- el[-length(el)]
  
}

pred_act <- pred_act[c(el,pi),]

six_tracklet_pred <- c()

for(i in seq(1,nrow(pred_act),6)){
  j=i+5
  
  this.dat <- prod(pred_act$pred[i:j])/sum(prod(pred_act$pred[i:j]),prod(1-pred_act$pred[i:j]))
  
  six_tracklet_pred <- c(six_tracklet_pred,this.dat)
}

six_tracklet_pred <- data.frame(six_tracklet_pred)

six_tracklet_pred <- na.omit(six_tracklet_pred)

six_tracklet_real <- c()

for(i in seq(1,nrow(pred_act),6)){
  this.dat <- pred_act$act[i]
  six_tracklet_real <- c(six_tracklet_real,this.dat)
  
}

six_tracklet_real <- data.frame(six_tracklet_real)

which(is.na(six_tracklet_real))

pred_act <- data.frame(cbind(six_tracklet_pred,six_tracklet_real))

elec_pi_eff_func <- function(model_1.preds,model_1.labels){
  
    # model_1.preds <- read.csv(model_1.preds,header=F, sep="")
    # 
    # model_1.labels <- read.csv(model_1.labels,header=F, sep="")
    
    model_1 <- data.frame(cbind(model_1.preds,model_1.labels))
    
    model_1.electrons <- which(model_1[,2]==1)
    
    electrons <- model_1[model_1.electrons,]
    
    pions <- model_1[-as.numeric(model_1.electrons),]
    
    electrons <- data.frame(electrons)
    
    names(electrons) <- c("prediction","label")
    
    pions <- data.frame(pions)
    
    names(pions) <- c("prediction","label")
    
    electron_efficiency <- function(electrons.,par){
  
    electrons <- electrons.
    
    electrons$electron_pred <- ifelse(electrons$prediction>=par[1],1,0)
    
    correct <- ifelse(electrons$electron_pred==electrons$label,1,0)
    
    error_metric <- sum(correct)/nrow(electrons)
    
    error_metric <- (error_metric-0.9)^2
    
    return(error_metric)
  
}

  res <- optim(par=c(0),fn=electron_efficiency,lower = 0,upper = 1,electrons.=electrons,method="Brent")
  
  require(ggplot2)

  g <- ggplot(pred_act,aes(pred_act[,1],colour=factor(pred_act[,2])))+geom_histogram(bins = 1000)+facet_wrap(factor(pred_act[,2]))
  print(g)
  
  hist(pred_act[,1],breaks=1000)
  abline(v=res$par,col="red")
  
  electrons$predicted_label <- ifelse(electrons$prediction>=res$par,1,0)
  
  print(paste0("Electron Efficiency: ",sum(electrons$predicted_label)/nrow(electrons)))
  
  pions$predicted_label <- ifelse(pions$prediction>=res$par,1,0)
  
  pions$misclassified_as_electron <- ifelse(pions$predicted_label==1,1,0)
  
  print(paste0("Pion Efficiency: ",(sum(pions$misclassified_as_electron)/nrow(pions))))
  
  pred_act$final_pred <- ifelse(pred_act[,1]>=res$par,1,0)
  
  require(caret)
  
  print(caret::confusionMatrix(data=factor(pred_act$final_pred),reference = factor(pred_act[,2])))
  print("--------------------------------------------------------------------------------------------------")
  
}

elec_pi_eff_func(pred_act[,1],pred_act[,2])


```

```{r}
rm(pred_act,six_tracklet_pred,six_tracklet_real,el,pi)

rm(preds,i,j,this.dat)
```

```{r}
K <- keras::backend()

require(tensorflow)

fokLos <- function(gamma=2., alpha=.25){
  
  loss <- function(y_true,y_pred){
  
  pt_1 <- tf$where(tf$equal(y_true,1),y_pred,tf$ones_like(y_pred))
  
  pt_0 <- tf$where(tf$equal(y_true,0),y_pred,tf$ones_like(y_pred))
  
  #clip to prevent NaNs and Infs
  
  epsilon <- K$epsilon()
  
  pt_1 <- K$clip(pt_1,epsilon,1.-epsilon)
  pt_0 <- K$clip(pt_0,epsilon,1.-epsilon)
  
  return(-K$mean(alpha*K$pow(1.-pt_1,gamma)*K$log(pt_1))-K$mean((1-alpha)*K$pow(pt_0,gamma)*K$log(1.-pt_0)))
    
  }
  
 return(loss)
}
```




```{r}
model %>% compile(
  loss = fokLos(),
  optimizer = optimizer_adam(lr=0.00001),
  metrics = c("accuracy")
)

history <- model %>% fit(
  x3, y3, 
  epochs = 5, batch_size = 256, 
  validation_split = 0.2,
  shuffle=T
)

plot(history)
```




```{r}
save_model_hdf5(model, "C:/Users/gerhard/Documents/MSc-thesis/NEW/ML/model_focal_loss_mt_2_lt_3_GeV.h5", overwrite = TRUE,
  include_optimizer = TRUE)
```

```{r}
require(keras)

rm(list=ls())

load("C:/Users/gerhard/documents/msc-thesis-data/x_P3")
load("C:/Users/gerhard/documents/msc-thesis-data/y_P3")

# dim(x2)
dim(x3) <- c(dim(x3)[1],17,24,1)

# x <- (x3-max(x3))/max(x3)

require(keras)

model <- keras_model_sequential() %>%
  layer_conv_2d(input_shape = c(17,24,1),filters = 32,kernel_size = c(6,6),padding = "same",activation = "tanh") %>%
  layer_max_pooling_2d() %>%
  layer_dropout(rate=0.2) %>%
  layer_conv_2d(64,c(3,3),activation = "tanh",padding="same") %>%
  layer_max_pooling_2d() %>%
  layer_dropout(rate=0.2) %>%
  layer_conv_2d(128,c(3,3),activation = "tanh",padding="same") %>%
  layer_max_pooling_2d() %>%
  layer_dropout(rate=0.2) %>%
  layer_flatten() %>%
  layer_dense(512,"tanh") %>%
  layer_dropout(rate=0.2) %>%
  layer_dense(256,"tanh") %>%
  layer_dropout(rate=0.2) %>%
  layer_dense(128,"tanh") %>%
  layer_dropout(rate=0.2) %>%
  layer_dense(1,activation = "sigmoid")

model <- keras::load_model_weights_hdf5(model,filepath = "C:/Users/gerhard/Documents/MSc-thesis/NEW/ML/model_focal_loss_mt_2_lt_3_GeV.h5")


preds <- predict(model,x3)

pred_act <- cbind(preds,y3)

pred_act <- data.frame(pred_act)

names(pred_act) <- c("pred","act")

pi <- which(pred_act$act==1)
el <- which(pred_act$act!=1)

while(length(pi)%%6!=0){
  #print(length(pi))
  pi <- pi[-length(pi)]
  
}

while(length(el)%%6!=0){
  #print(length(el))
  el <- el[-length(el)]
  
}

pred_act <- pred_act[c(el,pi),]

six_tracklet_pred <- c()

for(i in seq(1,nrow(pred_act),6)){
  j=i+5
  
  this.dat <- prod(pred_act$pred[i:j])/sum(prod(pred_act$pred[i:j]),prod(1-pred_act$pred[i:j]))
  
  six_tracklet_pred <- c(six_tracklet_pred,this.dat)
}

six_tracklet_pred <- data.frame(six_tracklet_pred)

six_tracklet_pred <- na.omit(six_tracklet_pred)

six_tracklet_real <- c()

for(i in seq(1,nrow(pred_act),6)){
  this.dat <- pred_act$act[i]
  six_tracklet_real <- c(six_tracklet_real,this.dat)
  
}

six_tracklet_real <- data.frame(six_tracklet_real)

which(is.na(six_tracklet_real))

pred_act <- data.frame(cbind(six_tracklet_pred,six_tracklet_real))

elec_pi_eff_func <- function(model_1.preds,model_1.labels){
  
    # model_1.preds <- read.csv(model_1.preds,header=F, sep="")
    # 
    # model_1.labels <- read.csv(model_1.labels,header=F, sep="")
    
    model_1 <- data.frame(cbind(model_1.preds,model_1.labels))
    
    model_1.electrons <- which(model_1[,2]==1)
    
    electrons <- model_1[model_1.electrons,]
    
    pions <- model_1[-as.numeric(model_1.electrons),]
    
    electrons <- data.frame(electrons)
    
    names(electrons) <- c("prediction","label")
    
    pions <- data.frame(pions)
    
    names(pions) <- c("prediction","label")
    
    electron_efficiency <- function(electrons.,par){
  
    electrons <- electrons.
    
    electrons$electron_pred <- ifelse(electrons$prediction>=par[1],1,0)
    
    correct <- ifelse(electrons$electron_pred==electrons$label,1,0)
    
    error_metric <- sum(correct)/nrow(electrons)
    
    error_metric <- (error_metric-0.9)^2
    
    return(error_metric)
  
}

  res <- optim(par=c(0),fn=electron_efficiency,lower = 0,upper = 1,electrons.=electrons,method="Brent")
  
  require(ggplot2)
  
  g <- ggplot(pred_act,aes(pred_act[,1],colour=factor(pred_act[,2])))+geom_histogram(bins = 1000)+facet_wrap(factor(pred_act[,2]))
  print(g)
  
  hist(pred_act[,1],breaks=1000)
  abline(v=res$par,col="red")
  
  electrons$predicted_label <- ifelse(electrons$prediction>=res$par,1,0)
  
  print(paste0("Electron Efficiency: ",sum(electrons$predicted_label)/nrow(electrons)))
  
  pions$predicted_label <- ifelse(pions$prediction>=res$par,1,0)
  
  pions$misclassified_as_electron <- ifelse(pions$predicted_label==1,1,0)
  
  print(paste0("Pion Efficiency: ",(sum(pions$misclassified_as_electron)/nrow(pions))))
  
  pred_act$final_pred <- ifelse(pred_act[,1]>=res$par,1,0)
  
  require(caret)
  
  print(caret::confusionMatrix(data=factor(pred_act$final_pred),reference = factor(pred_act[,2])))
  print("--------------------------------------------------------------------------------------------------")
  
}

elec_pi_eff_func(pred_act[,1],pred_act[,2])
```


```{r}
rm(pred_act,preds,six_tracklet_pred,six_tracklet_real,el,i,j,pi,this.dat,x3,y3)
```

```{r}
model %>% compile(
  loss = fokLos(),
  optimizer = optimizer_adam(lr=0.00001),
  metrics = c("accuracy")
)

history <- model %>% fit(
  x4, y4, 
  epochs = 5, batch_size = 256, 
  validation_split = 0.2,
  shuffle=T
)

plot(history)
```

```{r}

```



```{r}

load("C:/Users/gerhard/documents/msc-thesis-data/x_P4")
load("C:/Users/gerhard/documents/msc-thesis-data/y_P4")

# dim(x2)
dim(x4) <- c(dim(x4)[1],17,24,1)

# x <- (x3-max(x3))/max(x3)


require(keras)

model <- keras_model_sequential() %>%
  layer_conv_2d(input_shape = c(17,24,1),filters = 32,kernel_size = c(6,6),padding = "same",activation = "tanh") %>%
  layer_max_pooling_2d() %>%
  layer_dropout(rate=0.2) %>%
  layer_conv_2d(64,c(3,3),activation = "tanh",padding="same") %>%
  layer_max_pooling_2d() %>%
  layer_dropout(rate=0.2) %>%
  layer_conv_2d(128,c(3,3),activation = "tanh",padding="same") %>%
  layer_max_pooling_2d() %>%
  layer_dropout(rate=0.2) %>%
  layer_flatten() %>%
  layer_dense(512,"tanh") %>%
  layer_dropout(rate=0.2) %>%
  layer_dense(256,"tanh") %>%
  layer_dropout(rate=0.2) %>%
  layer_dense(128,"tanh") %>%
  layer_dropout(rate=0.2) %>%
  layer_dense(1,activation = "sigmoid")

model <- keras::load_model_weights_hdf5(model,filepath = "C:/Users/gerhard/Documents/MSc-thesis/NEW/ML/model_focal_loss_mt_2_lt_3_GeV.h5")


preds <- predict(model,x4)

pred_act <- cbind(preds,y4)

pred_act <- data.frame(pred_act)

names(pred_act) <- c("pred","act")

pi <- which(pred_act$act==1)
el <- which(pred_act$act!=1)

while(length(pi)%%6!=0){
  #print(length(pi))
  pi <- pi[-length(pi)]
  
}

while(length(el)%%6!=0){
  #print(length(el))
  el <- el[-length(el)]
  
}

pred_act <- pred_act[c(el,pi),]

six_tracklet_pred <- c()

for(i in seq(1,nrow(pred_act),6)){
  j=i+5
  
  this.dat <- prod(pred_act$pred[i:j])/sum(prod(pred_act$pred[i:j]),prod(1-pred_act$pred[i:j]))
  
  six_tracklet_pred <- c(six_tracklet_pred,this.dat)
}

six_tracklet_pred <- data.frame(six_tracklet_pred)

six_tracklet_pred <- na.omit(six_tracklet_pred)

six_tracklet_real <- c()

for(i in seq(1,nrow(pred_act),6)){
  this.dat <- pred_act$act[i]
  six_tracklet_real <- c(six_tracklet_real,this.dat)
  
}

six_tracklet_real <- data.frame(six_tracklet_real)

which(is.na(six_tracklet_real))

pred_act <- data.frame(cbind(six_tracklet_pred,six_tracklet_real))

elec_pi_eff_func <- function(model_1.preds,model_1.labels){
  
    # model_1.preds <- read.csv(model_1.preds,header=F, sep="")
    # 
    # model_1.labels <- read.csv(model_1.labels,header=F, sep="")
    
    model_1 <- data.frame(cbind(model_1.preds,model_1.labels))
    
    model_1.electrons <- which(model_1[,2]==1)
    
    electrons <- model_1[model_1.electrons,]
    
    pions <- model_1[-as.numeric(model_1.electrons),]
    
    electrons <- data.frame(electrons)
    
    names(electrons) <- c("prediction","label")
    
    pions <- data.frame(pions)
    
    names(pions) <- c("prediction","label")
    
    electron_efficiency <- function(electrons.,par){
  
    electrons <- electrons.
    
    electrons$electron_pred <- ifelse(electrons$prediction>=par[1],1,0)
    
    correct <- ifelse(electrons$electron_pred==electrons$label,1,0)
    
    error_metric <- sum(correct)/nrow(electrons)
    
    error_metric <- (error_metric-0.9)^2
    
    return(error_metric)
  
}

  res <- optim(par=c(0),fn=electron_efficiency,lower = 0,upper = 1,electrons.=electrons,method="Brent")
  
  require(ggplot2)
  
  g <- ggplot(pred_act,aes(pred_act[,1],colour=factor(pred_act[,2])))+geom_histogram(bins = 1000)+facet_wrap(factor(pred_act[,2]))
  print(g)
  
  hist(pred_act[,1],breaks=1000)
  abline(v=res$par,col="red")
  
  electrons$predicted_label <- ifelse(electrons$prediction>=res$par,1,0)
  
  print(paste0("Electron Efficiency: ",sum(electrons$predicted_label)/nrow(electrons)))
  
  pions$predicted_label <- ifelse(pions$prediction>=res$par,1,0)
  
  pions$misclassified_as_electron <- ifelse(pions$predicted_label==1,1,0)
  
  print(paste0("Pion Efficiency: ",(sum(pions$misclassified_as_electron)/nrow(pions))))
  
  pred_act$final_pred <- ifelse(pred_act[,1]>=res$par,1,0)
  
  require(caret)
  
  print(caret::confusionMatrix(data=factor(pred_act$final_pred),reference = factor(pred_act[,2])))
  print("--------------------------------------------------------------------------------------------------")
  
}

elec_pi_eff_func(pred_act[,1],pred_act[,2])
```

























































